# Example environment configuration (DO NOT COMMIT REAL SECRETS)
#
# Copy this file to `.env` (ignored by default) and export the variables in your shell,
# or use a tool like direnv.

# Select the default provider for `--adapter auto`.
# Supported: github, foundry, openai, dummy
TRIAGE_PROVIDER=github

# -----------------------------
# GitHub Models
# -----------------------------
# GitHub token with permission to use GitHub Models.
TRIAGE_GITHUB_TOKEN=ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Optional. Default is openai/gpt-4.1
TRIAGE_GITHUB_MODEL=openai/gpt-4.1

# Optional. If set, requests are sent to the org-attributed endpoint.
TRIAGE_GITHUB_ORG=

# Optional overrides
TRIAGE_GITHUB_BASE_URL=https://models.github.ai
TRIAGE_GITHUB_API_VERSION=2022-11-28

# -----------------------------
# Microsoft Foundry (Azure AI inference endpoint)
# -----------------------------
# Example endpoint:
# https://<resource-name>.services.ai.azure.com/models
TRIAGE_FOUNDRY_ENDPOINT=

# Set one of the following credentials.
TRIAGE_FOUNDRY_API_KEY=
# AZURE_INFERENCE_CREDENTIAL=

# Deployment name in your Foundry resource.
TRIAGE_FOUNDRY_MODEL=

# Optional
TRIAGE_FOUNDRY_API_VERSION=2024-05-01-preview

# -----------------------------
# Shared knobs
# -----------------------------
TRIAGE_JSON_MODE=true
TRIAGE_TEMPERATURE=0.2
TRIAGE_SEED=
