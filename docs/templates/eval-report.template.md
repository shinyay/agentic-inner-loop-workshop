# Evaluation report

Date/time:

Version evaluated:

Model/provider (if applicable):

Dataset:

## 1. Summary

- What changed since the last version?
- What did you expect to improve?

## 2. Metrics

Write down the key numbers you care about.

Example:

- Type accuracy: 0.75 → 0.82
- Priority accuracy: 0.68 → 0.73
- Label F1: 0.51 → 0.60

## 3. Representative failures

Pick 3–5 failure cases.

For each:

- Input (title/body)
- Expected output
- Actual output
- Why it failed (hypothesis)
- What change could fix it?

## 4. Actions

Convert insights into small tasks.

Each action should include:

- Title
- DoD
- How to validate (unit test or AI Toolkit eval step)

## 5. Notes

Anything surprising?
